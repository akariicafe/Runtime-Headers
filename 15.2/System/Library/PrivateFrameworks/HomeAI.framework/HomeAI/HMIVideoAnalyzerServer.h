@class HMIVideoFrameAnalyzer, NSDate, NSObject, HMIVideoDecoder, HMIVideoTimeline, HMIVideoPackageAnalyzer, HMIVideoEncoder, HMIVideoCommandBuffer, HMIVideoEventBuffer, NSString, HMIVideoTemporalEventFilter, HMIVideoFrameSampler, NSData, HMIVideoAssetWriter, HMIVideoFrameSelector;
@protocol OS_dispatch_queue;

@interface HMIVideoAnalyzerServer : HMIVideoAnalyzer <HMIVideoCommandBufferDelegate, HMIVideoDecoderDelegate, HMIVideoEncoderDelegate, HMIVideoFrameSelectorDelegate, HMIVideoFrameAnalyzerDelegate, HMIVideoAssetWriterDelegate, HMIVideoFrameSamplerDelegate, HMIVideoPackageAnalyzerDelegate> {
    long long _numDecodedSamples;
    long long _numDidAnalyzeFrames;
    long long _numDidAnalyzePackages;
    long long _numDidAnalyzeFragments;
    long long _numDidCreateTimelapseFragments;
    BOOL _monitored;
    BOOL _encode;
    double _analysisFPS;
}

@property (readonly) NSObject<OS_dispatch_queue> *inputQueue;
@property (readonly) NSObject<OS_dispatch_queue> *workQueue;
@property (readonly) NSObject<OS_dispatch_queue> *encoderQueue;
@property const struct opaqueCMFormatDescription { } *inputVideoFormat;
@property const struct opaqueCMFormatDescription { } *inputAudioFormat;
@property const struct opaqueCMFormatDescription { } *timelapseOutputVideoFormat;
@property (readonly) HMIVideoCommandBuffer *commandBuffer;
@property (readonly) HMIVideoDecoder *decoder;
@property (readonly) HMIVideoFrameSampler *frameThumbnailSampler;
@property (readonly) HMIVideoFrameSampler *frameTimelapseSampler;
@property (retain) HMIVideoEncoder *encoder;
@property (retain) HMIVideoEncoder *timelapseEncoder;
@property (readonly) HMIVideoFrameSelector *frameSelector;
@property (readonly) HMIVideoFrameAnalyzer *frameAnalyzer;
@property (retain) HMIVideoAssetWriter *assetWriter;
@property (retain) HMIVideoAssetWriter *timelapseAssetWriter;
@property struct { long long value; int timescale; unsigned int flags; long long epoch; } currentPTS;
@property struct { long long value; int timescale; unsigned int flags; long long epoch; } currentDTS;
@property (readonly) HMIVideoEventBuffer *frameAnalyzerFrameResultBuffer;
@property (readonly) HMIVideoEventBuffer *packageAnalyzerFrameResultBuffer;
@property (readonly) HMIVideoEventBuffer *thumbnailBuffer;
@property (retain) NSData *initializationSegment;
@property (retain) NSData *timelapseInitializationSegment;
@property (readonly) HMIVideoEventBuffer *dynamicConfigurationBuffer;
@property (readonly) HMIVideoPackageAnalyzer *packageAnalyzer;
@property (readonly) HMIVideoTemporalEventFilter *temporalEventFilter;
@property (readonly) HMIVideoTimeline *timeline;
@property (readonly) NSDate *startDate;
@property (readonly) double timeSinceAnalyzerStarted;
@property (retain) NSDate *lastFragmentRecievedDate;
@property (readonly) double timeSinceLastFragmentWasReceived;
@property BOOL hasFailed;
@property (getter=isCancelled) BOOL cancelled;
@property (readonly) unsigned long long hash;
@property (readonly) Class superclass;
@property (readonly, copy) NSString *description;
@property (readonly, copy) NSString *debugDescription;

- (void)flush;
- (double)delay;
- (BOOL)encode;
- (unsigned long long)status;
- (id)state;
- (void).cxx_destruct;
- (void)finishWithCompletionHandler:(id /* block */)a0;
- (void)dealloc;
- (void)cancel;
- (void)flushAsync;
- (void)_notifyDelegateDidFailWithError:(id)a0;
- (void)frameAnalyzer:(id)a0 didAnalyzeFrame:(id)a1 error:(id)a2;
- (void)frameAnalyzer:(id)a0 didProduceAnalysisStateUpdate:(id)a1;
- (void)frameSampler:(id)a0 didSampleFrame:(struct opaqueCMSampleBuffer { } *)a1;
- (void)encoder:(id)a0 didFailWithError:(id)a1;
- (void)encoder:(id)a0 didEncodeSampleBuffer:(struct opaqueCMSampleBuffer { } *)a1;
- (double)analysisFPS;
- (BOOL)monitored;
- (void)setAnalysisFPS:(double)a0;
- (void)packageAnalyzer:(id)a0 didDetectPackagesWithResult:(id)a1 error:(id)a2;
- (void)buffer:(id)a0 willHandleSampleBuffer:(struct opaqueCMSampleBuffer { } *)a1;
- (void)bufferWillFlush:(id)a0;
- (void)decoder:(id)a0 didDecodeSampleBuffer:(struct opaqueCMSampleBuffer { } *)a1;
- (void)decoder:(id)a0 didFailWithError:(id)a1;
- (void)assetWriter:(id)a0 didOutputInitializationSegment:(id)a1;
- (void)assetWriter:(id)a0 didOutputSeparableSegment:(id)a1 segmentReport:(id)a2;
- (void)assetWriter:(id)a0 didFailWithError:(id)a1;
- (void)frameSelector:(id)a0 didSelectFrame:(struct opaqueCMSampleBuffer { } *)a1 motionDetections:(id)a2 motionScore:(double)a3;
- (void)frameSelector:(id)a0 didDetectMotion:(id)a1 inFrame:(struct opaqueCMSampleBuffer { } *)a2;
- (id)initWithConfiguration:(id)a0 identifier:(id)a1;
- (void)handleAssetData:(id)a0 withOptions:(id)a1 completionHandler:(id /* block */)a2;
- (void)handleMessageWithOptions:(id)a0 completionHandler:(id /* block */)a1;
- (void)setMonitored:(BOOL)a0;
- (void)setEncode:(BOOL)a0;
- (void)_saveFragmentDataToDisk:(id)a0 diskBufferSize:(unsigned long long)a1;
- (void)_prepareForInputVideoFormat:(const struct opaqueCMFormatDescription { } *)a0 audioFormat:(const struct opaqueCMFormatDescription { } *)a1;
- (void)_ensureDecoderForFragment:(id)a0;
- (void)_ensureEncoder;
- (void)_ensureTimelapseEncoder;
- (void)handleSampleBuffer:(struct opaqueCMSampleBuffer { } *)a0 errorHandler:(id /* block */)a1;
- (void)_handleDecodedSampleBuffer:(struct opaqueCMSampleBuffer { } *)a0;
- (void)_configureAssetWriter;
- (void)_configureTimelapseAssetWriter;
- (void)_configureEncoder;
- (void)_configureTimelapseEncoder;
- (void)_prepareForTimelapseOutputVideoFormat:(const struct opaqueCMFormatDescription { } *)a0;
- (id)dynamicConfigurationForTime:(struct { long long x0; int x1; unsigned int x2; long long x3; })a0;
- (id)_filterFrameResult:(id)a0 dynamicConfiguration:(id)a1 motionDetections:(id)a2;
- (void)_notifyDelegateDidAnalyzeFrameWithResult:(id)a0;
- (void)_notifyDelegateDidProduceAnalysisStateUpdate:(id)a0;
- (void)_notifyDelegateDidCreateTimelapseFragment:(id)a0;
- (void)_notifyDelegateDidAnalyzeFragmentWithResult:(id)a0;
- (void)_produceResult:(SEL)a0 withArguments:(id)a1;

@end
