@class NSString, NSURL, AVURLAsset, NSSet, AVAssetReader, NSDictionary, AVAssetReaderTrackOutput, NSObject, NSMutableArray, ARImageCroppingTechnique, ARSessionReplayStats, AVAssetReaderOutputMetadataAdaptor;
@protocol ARReplaySensorDelegate, ARSensorDelegate, OS_dispatch_source, OS_dispatch_queue;

@interface ARReplaySensor : NSObject <ARInternalSessionObserver, ARReplaySensorProtocolInternal, ARReplaySensorProtocol> {
    BOOL _manualCommandLineMode;
    AVURLAsset *_asset;
    NSMutableArray *_arImageData;
    NSMutableArray *_arAccelerometerData;
    NSMutableArray *_arGyroData;
    NSMutableArray *_arDeviceOrientationData;
    NSMutableArray *_arLocationData;
    id /* block */ _customDataGetter;
    NSDictionary *_recordedResultGetters;
    double _originalToReplayTimestampDifference;
    NSObject<OS_dispatch_queue> *_replayQueue;
    id<ARReplaySensorDelegate> _traceReplaySensorDelegate;
    NSObject<OS_dispatch_source> *_timer;
    double _startTime;
    long long _tick;
    int _imageIndexForPreloading;
    int _accelDataIndex;
    int _gyroDataIndex;
    int _deviceOrientationDataIndex;
    int _locationDataIndex;
    BOOL _running;
    BOOL _metadataLoadedFromAsset;
    BOOL _replayStarted;
    _Atomic BOOL _finishedReplaying;
    struct opaqueCMSampleBuffer { } *_nextSampleBuffer;
    AVAssetReader *_assetReader;
    AVAssetReaderTrackOutput *_imageOutput;
    AVAssetReaderTrackOutput *_depthOutput;
    struct opaqueCMSampleBuffer { } *_nextDepthSampleBuffer;
    AVAssetReaderOutputMetadataAdaptor *_oldMotionOutputMetadataAdaptor;
    AVAssetReaderOutputMetadataAdaptor *_accelOutputMetadataAdaptor;
    AVAssetReaderOutputMetadataAdaptor *_gyroOutputMetadataAdaptor;
    AVAssetReaderOutputMetadataAdaptor *_imageOutputMetadataAdaptor;
    AVAssetReaderOutputMetadataAdaptor *_accelOutputMetadataAdaptor_CV3D;
    AVAssetReaderOutputMetadataAdaptor *_gyroOutputMetadataAdaptor_CV3D;
    AVAssetReaderOutputMetadataAdaptor *_deviceMotionOutputMetadataAdaptor_CV3D;
    AVAssetReaderOutputMetadataAdaptor *_locationMetadataAdaptor_CV3D;
    AVAssetReaderOutputMetadataAdaptor *_imageOutputMetadataAdaptor_CV3D;
    AVAssetReaderOutputMetadataAdaptor *_deviceOrientationOutputMetadataAdaptor;
    AVAssetReaderOutputMetadataAdaptor *_customDataOutputMetadataAdaptor;
    NSDictionary *_recordedResultAdaptors;
    BOOL _displaySynchronizationMarker;
    long long _displaySynchronizationMarkerFrames;
    struct __CVBuffer { } *_synchronizationMarker;
    struct __CVPixelBufferPool { } *_synchronizationMarkerPool;
    struct OpaqueVTPixelTransferSession { } *_synchronizationTransferSession;
    unsigned long long _sensorDataTypes;
    ARImageCroppingTechnique *_croppingTechnique;
    ARSessionReplayStats *_determinedReplayStats;
}

@property (nonatomic) int imageIndex;
@property long long nextFrameIndex;
@property long long targetFrameIndex;
@property (weak, nonatomic) id<ARSensorDelegate> delegate;
@property (weak) id<ARReplaySensorDelegate> replaySensorDelegate;
@property (readonly, nonatomic) NSURL *sequenceURL;
@property (readonly, nonatomic) NSString *deviceModel;
@property (readonly, nonatomic) NSString *osVersion;
@property (readonly, nonatomic) NSString *arkitVersion;
@property (readonly, nonatomic) struct CGSize { double width; double height; } imageResolution;
@property (readonly, nonatomic) double nominalFrameRate;
@property (readonly, nonatomic) unsigned long long recordedSensorTypes;
@property (readonly, nonatomic) long long replayMode;
@property (readonly, nonatomic) BOOL isReplayingManually;
@property (readonly, nonatomic, getter=isSynchronousMode) BOOL synchronousMode;
@property float advanceFramesPerSecondMultiplier;
@property (copy, nonatomic) NSSet *customDataClasses;
@property (readonly, nonatomic) BOOL interrupted;
@property (readonly) unsigned long long hash;
@property (readonly) Class superclass;
@property (readonly, copy) NSString *description;
@property (readonly, copy) NSString *debugDescription;
@property (weak) id<ARReplaySensorDelegate> traceReplaySensorDelegate;
@property (nonatomic) unsigned long long powerUsage;
@property (readonly, nonatomic) BOOL finishedReplaying;

- (void)interrupt;
- (void)tick;
- (void)endInterruption;
- (void)advance;
- (void)start;
- (void).cxx_destruct;
- (BOOL)isEqual:(id)a0;
- (double)currentTime;
- (void)observeValueForKeyPath:(id)a0 ofObject:(id)a1 change:(id)a2 context:(void *)a3;
- (void)failWithError:(id)a0;
- (void)dealloc;
- (BOOL)hasMoreData;
- (void)stop;
- (unsigned long long)providedDataTypes;
- (id)initWithDataFromFile:(id)a0;
- (id)initWithSequenceURL:(id)a0 replayMode:(long long)a1;
- (id)initWithSequenceURL:(id)a0 manualReplay:(BOOL)a1;
- (id)initWithSequenceURL:(id)a0 manualReplay:(BOOL)a1 synchronousMode:(BOOL)a2;
- (void)advanceFrame;
- (void)advanceToFrameIndex:(long long)a0;
- (id)customDataForTimestamp:(double)a0;
- (void)readFileMetadataFromAsset:(id)a0;
- (void)endReplay;
- (void)prepareForReplay;
- (void)startReplayIfNeeded;
- (void)initializeAssetReaderWithAsset:(id)a0 buffersOnly:(BOOL)a1;
- (void)loadAllMetadata;
- (void)fastForwardIndexesToTime:(double)a0;
- (void)preloadNextPixelBuffers:(int)a0;
- (BOOL)track:(id)a0 hasMetadataIdentifier:(id)a1;
- (id)createAndAddMetadataAdaptorForTrack:(id)a0;
- (id)unpackItemsOfClass:(Class)a0 withIdentifier:(id)a1 inOutputAdaptor:(id)a2;
- (void)enumerateDataWithIdentifier:(id)a0 inOutputAdaptor:(id)a1 usingBlock:(id /* block */)a2;
- (id)unpackTimestampedCV3DDictionaryItemsOfClass:(Class)a0 withIdentifier:(id)a1 inOutputAdaptor:(id)a2;
- (id)unpackTimestampedItemsOfClasses:(id)a0 withIdentifier:(id)a1 inOutputAdaptor:(id)a2;
- (id /* block */)createResultForTimestampGetterBlockFromTimestampedResults:(id)a0;
- (BOOL)hasImageDataForTimestamp:(double)a0;
- (id)getNextImageData;
- (BOOL)hasAccelerometerDataForTime:(double)a0;
- (id)getNextAccelerometerData;
- (void)_didOutputSensorData:(id)a0;
- (BOOL)hasGyroDataForTime:(double)a0;
- (id)getNextGyroData;
- (BOOL)hasDeviceOrientationDataForTime:(double)a0;
- (id)getNextDeviceOrientationData;
- (BOOL)hasLocationDataForTime:(double)a0;
- (id)getNextLocationData;
- (struct __CVBuffer { } *)requestNextPixelBufferForTimestamp:(double)a0;
- (struct __CVBuffer { } *)requestNextDepthPixelBufferForTimestamp:(double)a0;
- (id)getResultDataForClasses:(id)a0 atTimestamp:(double)a1;

@end
