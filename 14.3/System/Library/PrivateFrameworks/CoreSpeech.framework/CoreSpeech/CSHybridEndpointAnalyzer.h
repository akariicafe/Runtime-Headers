@class NSDate, NSString, EARCaesuraSilencePosteriorGenerator, NSDictionary, _EAREndpointer, NSObject, CSAsset, EARClientSilenceFeatures, CSServerEndpointFeatures, NSMutableArray;
@protocol OS_dispatch_queue, CSEndpointAnalyzerDelegate, CSEndpointAnalyzerImplDelegate;

@interface CSHybridEndpointAnalyzer : NSObject <CSAssetManagerDelegate, CSFirstUnlockMonitorDelegate, EARCaesuraSilencePosteriorGeneratorDelegate, CSEndpointAnalyzerImpl>

@property (retain, nonatomic) CSAsset *currentAsset;
@property (retain, nonatomic) NSObject<OS_dispatch_queue> *apQueue;
@property (nonatomic) unsigned long long numSamplesProcessed;
@property (nonatomic) BOOL didAddAudio;
@property (retain, nonatomic) EARCaesuraSilencePosteriorGenerator *caesuraSPG;
@property (retain, nonatomic) EARClientSilenceFeatures *clientSilenceFeaturesAtEndpoint;
@property (nonatomic) BOOL canProcessCurrentRequest;
@property (retain, nonatomic) _EAREndpointer *hybridClassifier;
@property (retain, nonatomic) NSString *endpointerModelVersion;
@property (retain, nonatomic) NSObject<OS_dispatch_queue> *serverFeaturesQueue;
@property (retain, nonatomic) CSServerEndpointFeatures *lastKnownServerEPFeatures;
@property (retain, nonatomic) EARClientSilenceFeatures *lastKnownClientEPFeatures;
@property (retain, nonatomic) NSMutableArray *serverFeatureLatencies;
@property (nonatomic) double lastKnowServerFeaturesLatency;
@property (nonatomic) BOOL epResult;
@property (nonatomic) double serverFeaturesWarmupLatency;
@property (retain, nonatomic) NSDate *lastServerFeatureTimestamp;
@property (nonatomic) BOOL didReceiveServerFeatures;
@property (nonatomic) double clientLagThresholdMs;
@property (nonatomic) double clampedSFLatencyMsForClientLag;
@property (nonatomic) BOOL useDefaultServerFeaturesOnClientLag;
@property (retain, nonatomic) NSObject<OS_dispatch_queue> *hybridClassifierQueue;
@property (nonatomic) double lastReportedEndpointTimeMs;
@property (nonatomic) double processedAudioInSeconds;
@property (nonatomic) float lastEndpointPosterior;
@property (retain, nonatomic) NSObject<OS_dispatch_queue> *stateSerialQueue;
@property (nonatomic) BOOL didCommunicateEndpoint;
@property (nonatomic) unsigned long long currentRequestSampleRate;
@property (nonatomic) double vtExtraAudioAtStartInMs;
@property (nonatomic) unsigned long long vtEndInSampleCount;
@property (nonatomic) double hepAudioOriginInMs;
@property (retain, nonatomic) NSDictionary *recordContext;
@property (nonatomic) BOOL speechEndpointDetected;
@property (retain, nonatomic) NSDate *firstAudioPacketTimestamp;
@property (nonatomic) double firstAudioSampleSensorTimestamp;
@property (nonatomic) BOOL didTimestampFirstAudioPacket;
@property (nonatomic) BOOL recordingDidStop;
@property (retain, nonatomic) NSObject<OS_dispatch_queue> *silencePosteriorGeneratorQueue;
@property (nonatomic) BOOL didDetectSpeech;
@property (nonatomic) double elapsedTimeWithNoSpeech;
@property (nonatomic) double trailingSilenceDurationAtEndpoint;
@property (readonly) unsigned long long hash;
@property (readonly) Class superclass;
@property (readonly, copy) NSString *description;
@property (readonly, copy) NSString *debugDescription;
@property (weak, nonatomic) id<CSEndpointAnalyzerDelegate> delegate;
@property (weak, nonatomic) id<CSEndpointAnalyzerImplDelegate> implDelegate;
@property (nonatomic) unsigned long long activeChannel;
@property (nonatomic) long long endpointStyle;
@property (nonatomic) double delay;
@property (nonatomic) double startWaitTime;
@property (nonatomic) double automaticEndpointingSuspensionEndTime;
@property (nonatomic) double minimumDurationForEndpointer;
@property (readonly, nonatomic) double lastEndOfVoiceActivityTime;
@property (readonly, nonatomic) double lastStartOfVoiceActivityTime;
@property (nonatomic) double bypassSamples;
@property (nonatomic) long long endpointMode;
@property (nonatomic) double interspeechWaitTime;
@property (nonatomic) double endWaitTime;
@property (nonatomic) BOOL saveSamplesSeenInReset;

- (void)preheat;
- (void)CSFirstUnlockMonitor:(id)a0 didReceiveFirstUnlock:(BOOL)a1;
- (id)init;
- (void).cxx_destruct;
- (void)reset;
- (void)clientSilenceFeaturesAvailable:(id)a0;
- (void)CSLanguageCodeUpdateMonitor:(id)a0 didReceiveLanguageCodeChanged:(id)a1;
- (void)resetForNewRequestWithSampleRate:(unsigned long long)a0 recordContext:(id)a1 recordSettings:(id)a2;
- (void)processAudioSamplesAsynchronously:(id)a0;
- (void)stopEndpointer;
- (void)recordingStoppedForReason:(long long)a0;
- (void)processServerEndpointFeatures:(id)a0;
- (void)updateEndpointerThreshold:(float)a0;
- (void)updateEndpointerDelayedTrigger:(BOOL)a0;
- (void)shouldAcceptEagerResultForDuration:(double)a0 resultsCompletionHandler:(id /* block */)a1;
- (void)logFeaturesWithEvent:(id)a0 locale:(id)a1;
- (void)handleVoiceTriggerWithActivationInfo:(id)a0;
- (void)CSAssetManagerDidDownloadNewAsset:(id)a0;
- (void)_loadAndSetupEndpointerAssetIfNecessary;
- (void)_readParametersFromHEPAsset:(id)a0;
- (BOOL)_shouldUsePhaticWithRecordContext;
- (BOOL)_multimodalEndpointerEnabled;
- (id)serverFeaturesLatencyDistributionDictionary;
- (void)terminateProcessing;
- (id)_getCSHybridEndpointerConfigForAsset:(id)a0;
- (void)_updateAssetWithLanguage:(id)a0;
- (void)_updateAssetWithCurrentLanguage;

@end
